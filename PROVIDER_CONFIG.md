# Transkriptions-Provider Konfiguration

Diese App unterst√ºtzt flexible Transkriptions-Provider: **WhisperX** (lokal/remote) oder **ElevenLabs** (Cloud).

## Repositories f√ºr lokale Provider

- **WhisperX (HTTP/HTML API):** https://github.com/andreasknopke/WhisperX
- **Whisper-Live / Fast-Whisper (WebSocket API):** https://github.com/andreasknopke/Whisper-Live

Empfehlung: erst WhisperX stabil in Betrieb nehmen, danach Fast-Whisper f√ºr Realtime erg√§nzen.

## Konfigurations-Optionen

### ‚úÖ Option 1: WhisperX lokal (Empfohlen)

**Vorteile:**
- 100% lokal, keine Cloud
- Keine API-Kosten
- Beste Qualit√§t mit large-v2
- DSGVO-konform

**Setup:**
```bash
# In .env.local
TRANSCRIPTION_PROVIDER=whisperx
WHISPER_SERVICE_URL=http://localhost:5000
```

```bash
# WhisperX starten
docker-compose up -d whisper

# Oder ohne Docker:
cd whisper-service
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python app.py
```

**Repository-Hinweis:**
Wenn du den Service nicht aus diesem Repo-Ordner `whisper-service/` betreiben willst, nutze das dedizierte Repo:

```bash
cd /workspaces
git clone https://github.com/andreasknopke/WhisperX.git
cd WhisperX
# Start gem√§√ü README (Docker empfohlen)
```

---

### üåê Option 2: WhisperX remote

**Vorteile:**
- Zentraler WhisperX-Server f√ºr mehrere Clients
- Leichtgewichtiges Frontend
- Gleiche Qualit√§t wie lokal

**Setup:**
```bash
# In .env.local
TRANSCRIPTION_PROVIDER=whisperx
WHISPER_SERVICE_URL=https://your-whisper-server.com
```

**Server-Setup:**
```bash
# Auf deinem Server (z.B. Hetzner)
git clone <repo>
cd whisper-service
docker build -t whisperx .
docker run -d -p 5000:5000 --gpus all whisperx

# Oder mit docker-compose (siehe docker-compose.yml)
```

**Sicherheit f√ºr Remote-Setup:**
- Nutze HTTPS mit Reverse Proxy (nginx/Caddy)
- Aktiviere Basic Auth oder API-Keys
- Firewall: Nur bekannte IPs erlauben

Beispiel nginx Config:
```nginx
server {
    listen 443 ssl;
    server_name whisper.your-domain.com;
    
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    
    location / {
        auth_basic "WhisperX";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://localhost:5000;
    }
}
```

---

### ‚òÅÔ∏è Option 3: ElevenLabs Cloud

**Vorteile:**
- Keine eigene Infrastruktur n√∂tig
- Sofort einsatzbereit
- Keine Hardware-Anforderungen

**Nachteile:**
- Kosten: ~$0.10 pro Minute
- Daten gehen an Drittanbieter
- Internet-Verbindung erforderlich

**Setup:**
```bash
# In .env.local
TRANSCRIPTION_PROVIDER=elevenlabs
ELEVENLABS_API_KEY=your_elevenlabs_api_key
```

API-Key erhalten: https://elevenlabs.io/

---

### ‚ö° Option 4: Fast-Whisper lokal (WebSocket / Realtime)

**Vorteile:**
- Sehr niedrige Latenz f√ºr Live-Mitlesen
- Echtzeit-Streaming via WebSocket
- Lokal betreibbar

**Setup:**
```bash
# In .env.local
TRANSCRIPTION_PROVIDER=fast_whisper
FAST_WHISPER_WS_URL=ws://localhost:5001
```

**Installation (externes Repo):**
```bash
cd /workspaces
git clone https://github.com/andreasknopke/Whisper-Live.git
cd Whisper-Live
# Start gem√§√ü README (Docker oder Python)
```

**Wichtig:**
- Fast-Whisper wird in Schreibdienst prim√§r f√ºr Live-WebSocket genutzt.
- Serverseitige Batch-Wege fallen bei Bedarf auf WhisperX zur√ºck.

---

### üîÑ Option 5: WhisperX mit ElevenLabs Fallback

**Vorteile:**
- Prim√§r lokal (WhisperX)
- Fallback wenn WhisperX down ist
- Best of both worlds

**Setup:**
```bash
# In .env.local
TRANSCRIPTION_PROVIDER=whisperx
WHISPER_SERVICE_URL=http://localhost:5000
ELEVENLABS_API_KEY=your_key  # Wird nur bei Fehler verwendet
```

**Verhalten:**
1. Versucht WhisperX
2. Bei Fehler automatisch ElevenLabs
3. Logs zeigen welcher Provider genutzt wurde

---

## Provider-Wechsel

Einfach `.env.local` √§ndern und Next.js neu starten:

```bash
# .env.local bearbeiten
nano .env.local

# Next.js neu starten
npm run dev
```

Keine Code-√Ñnderungen n√∂tig!

---

## Kosten-Vergleich

### 100 Stunden Transkription pro Monat

| Provider | Setup-Kosten | Laufende Kosten | Gesamt |
|----------|--------------|-----------------|---------|
| WhisperX lokal | ‚Ç¨0 (oder Hardware) | ~‚Ç¨10 Strom | **‚Ç¨10/Monat** |
| WhisperX remote | ‚Ç¨18.50 (Hetzner CPX31) | ‚Ç¨0 | **‚Ç¨18.50/Monat** |
| ElevenLabs | ‚Ç¨0 | ‚Ç¨600 (100h √ó ‚Ç¨6/h) | **‚Ç¨600/Monat** |

---

## Performance-Vergleich

| Provider | Modell | Geschwindigkeit | Qualit√§t | Offline? |
|----------|--------|----------------|----------|----------|
| WhisperX lokal (GPU) | large-v2 | 2-4x Echtzeit | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ |
| WhisperX lokal (CPU) | medium | 10-20x Echtzeit | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ |
| WhisperX remote | large-v2 | 2-4x Echtzeit | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå |
| ElevenLabs | scribe_v1 | ~1x Echtzeit | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå |

---

## Empfehlungen

### F√ºr Entwicklung/Testing:
```bash
TRANSCRIPTION_PROVIDER=whisperx
WHISPER_SERVICE_URL=http://localhost:5000
WHISPER_MODEL=base  # Schnell zum Testen
```

### F√ºr Produktion (kleine Praxis):
```bash
TRANSCRIPTION_PROVIDER=whisperx
WHISPER_SERVICE_URL=http://localhost:5000
WHISPER_MODEL=large-v2  # Beste Qualit√§t
```

### F√ºr Produktion (mehrere Standorte):
```bash
TRANSCRIPTION_PROVIDER=whisperx
WHISPER_SERVICE_URL=https://central-whisper-server.com
WHISPER_MODEL=large-v2
```

### F√ºr Evaluierung/PoC:
```bash
TRANSCRIPTION_PROVIDER=elevenlabs
ELEVENLABS_API_KEY=your_key
# Schnell loslegen, sp√§ter zu WhisperX wechseln
```

---

## Troubleshooting

### WhisperX nicht erreichbar

**Problem:** `Error: WhisperX API error (connection refused)`

**L√∂sung:**
```bash
# WhisperX Service-Status pr√ºfen
curl http://localhost:5000/health

# Logs checken
docker-compose logs whisper

# Neu starten
docker-compose restart whisper
```

### ElevenLabs API-Fehler

**Problem:** `Error: ELEVENLABS_API_KEY not configured`

**L√∂sung:**
```bash
# API-Key in .env.local setzen
echo "ELEVENLABS_API_KEY=sk_..." >> .env.local

# Next.js neu starten
npm run dev
```

### Langsame Transkription

**WhisperX:**
- GPU verwenden (siehe [SETUP_LOCAL_GPU.md](SETUP_LOCAL_GPU.md))
- Kleineres Modell: `WHISPER_MODEL=medium`
- Batch-Size erh√∂hen

**ElevenLabs:**
- Bereits optimiert, ~1x Echtzeit

---

## Provider-Status anzeigen

Die API gibt den verwendeten Provider zur√ºck:

```json
{
  "text": "Transkribierter Text...",
  "segments": [...],
  "language": "de",
  "provider": "whisperx"  // oder "elevenlabs"
}
```

Im Browser-Console sieht man:
```
Transcription successful with whisperx
```

---

## Migrations-Guide

### Von ElevenLabs zu WhisperX wechseln

1. **WhisperX installieren:**
   ```bash
   docker-compose up -d whisper
   ```

2. **.env.local anpassen:**
   ```bash
   TRANSCRIPTION_PROVIDER=whisperx
   WHISPER_SERVICE_URL=http://localhost:5000
   # ELEVENLABS_API_KEY als Fallback behalten
   ```

3. **Testen:**
   ```bash
   curl -X POST http://localhost:3000/api/transcribe \
     -F "file=@test-audio.webm"
   ```

4. **Produktiv schalten:**
   - Monitoring aktivieren
   - Backup-Strategie f√ºr WhisperX-Service
   - Optional: ElevenLabs-Fallback behalten

### Von WhisperX zu Remote wechseln

1. **Remote Server aufsetzen:**
   ```bash
   # Auf Server
   git clone <repo>
   cd whisper-service
   docker-compose up -d
   ```

2. **Lokal nur URL √§ndern:**
   ```bash
   TRANSCRIPTION_PROVIDER=whisperx
   WHISPER_SERVICE_URL=https://your-server.com
   ```

Fertig! Keine Code-√Ñnderungen n√∂tig.

---

## Weitere Infos

- WhisperX Setup: [SETUP_LOCAL_GPU.md](SETUP_LOCAL_GPU.md)
- Docker Setup: [README.md](README.md#setup)
- Railway Cloud: [RAILWAY.md](RAILWAY.md)
